<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sparklyr on Random R Ramblings</title>
    <link>/tags/sparklyr/</link>
    <description>Recent content in sparklyr on Random R Ramblings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Sun, 22 Sep 2019 20:13:14 -0500</lastBuildDate>
    
        <atom:link href="/tags/sparklyr/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Selecting the max value from each group, a case study: dplyr and sparklyr</title>
      <link>/2019/09/22/selecting-the-max-value-from-each-group-a-case-study-dplyr-and-sparklyr/</link>
      <pubDate>Sun, 22 Sep 2019 20:13:14 -0500</pubDate>
      
      <guid>/2019/09/22/selecting-the-max-value-from-each-group-a-case-study-dplyr-and-sparklyr/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/proj4js/proj4.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/highcharts/css/motion.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;link href=&#34;/rmarkdown-libs/highcharts/css/htmlwdgtgrid.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/highcharts.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/highcharts-3d.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/highcharts-more.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/stock.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/map.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/annotations.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/boost.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/data.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/drag-panes.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/drilldown.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/item-series.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/offline-exporting.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/overlapping-datalabels.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/exporting.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/export-data.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/funnel.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/heatmap.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/treemap.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/sankey.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/solid-gauge.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/streamgraph.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/sunburst.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/vector.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/wordcloud.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/xrange.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/tilemap.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/venn.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/gantt.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/timeline.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/modules/parallel-coordinates.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/plugins/grouped-categories.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/plugins/motion.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/plugins/multicolor_series.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/custom/reset.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/custom/symbols-extra.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highcharts/custom/text-symbols.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/highchart-binding/highchart.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In my &lt;a href=&#34;https://nathaneastwood.github.io/2019/09/14/selecting-the-max-value-from-each-group-a-case-study-data.table/&#34;&gt;last post&lt;/a&gt; we looked at how to slice a &lt;code&gt;data.table&lt;/code&gt; by group to obtain the rows for which a particular column in that group is at its maximum value using the excellent &lt;code&gt;data.table&lt;/code&gt; package. In this post, we will be taking a look at how to perform this task using &lt;a href=&#34;https://github.com/tidyverse/dplyr&#34;&gt;&lt;code&gt;dplyr&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/rstudio/sparklyr&#34;&gt;&lt;code&gt;sparklyr&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dplyr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;dplyr&lt;/h1&gt;
&lt;p&gt;First, let’s take a look at our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
mtcars &amp;lt;- mtcars %&amp;gt;% 
  tibble::rownames_to_column(var = &amp;quot;car&amp;quot;) %&amp;gt;% 
  tibble::as_tibble()
mtcars
# # A tibble: 32 x 12
#    car      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#    &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#  1 Mazda…  21       6  160    110  3.9   2.62  16.5     0     1     4     4
#  2 Mazda…  21       6  160    110  3.9   2.88  17.0     0     1     4     4
#  3 Datsu…  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1
#  4 Horne…  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1
#  5 Horne…  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2
#  6 Valia…  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1
#  7 Duste…  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4
#  8 Merc …  24.4     4  147.    62  3.69  3.19  20       1     0     4     2
#  9 Merc …  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2
# 10 Merc …  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4
# # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So here, we are interested in getting a single car from each &lt;code&gt;cyl&lt;/code&gt; group whose &lt;code&gt;mpg&lt;/code&gt; is at the maximum for that group. I really like the &lt;code&gt;dplyr&lt;/code&gt; syntax for this problem, it’s really straight forward; take a look below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
  group_by(cyl) %&amp;gt;% 
  arrange(desc(mpg)) %&amp;gt;% 
  slice(1) %&amp;gt;% 
  ungroup()
# # A tibble: 3 x 12
#   car       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
# 1 Toyota…  33.9     4  71.1    65  4.22  1.84  19.9     1     1     4     1
# 2 Hornet…  21.4     6 258     110  3.08  3.22  19.4     1     0     3     1
# 3 Pontia…  19.2     8 400     175  3.08  3.84  17.0     0     0     3     2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We tell &lt;code&gt;dplyr&lt;/code&gt; to create groups of data for each of the &lt;code&gt;cyl&lt;/code&gt; levels and then within each group we &lt;code&gt;arrange()&lt;/code&gt; by &lt;code&gt;mpg&lt;/code&gt; in descending order. Once we have our data organised in this way it’s as simple as taking the top row from each group using &lt;code&gt;slice()&lt;/code&gt;. Of course there is more than one way we can achieve this task using &lt;code&gt;dplyr&lt;/code&gt;, take this next example for instance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
  group_by(cyl) %&amp;gt;% 
  arrange(desc(mpg)) %&amp;gt;% 
  mutate(row_number = row_number()) %&amp;gt;% 
  filter(row_number == 1) %&amp;gt;% 
  select(-row_number) %&amp;gt;% 
  ungroup()
# # A tibble: 3 x 12
#   car       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
# 1 Toyota…  33.9     4  71.1    65  4.22  1.84  19.9     1     1     4     1
# 2 Hornet…  21.4     6 258     110  3.08  3.22  19.4     1     0     3     1
# 3 Pontia…  19.2     8 400     175  3.08  3.84  17.0     0     0     3     2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It might not seem to be the most logical approach to this problem given we have access to the &lt;code&gt;slice()&lt;/code&gt; function but it feeds nicely into the &lt;a href=&#34;#sparklyr&#34;&gt;&lt;code&gt;sparklyr&lt;/code&gt;&lt;/a&gt; section.&lt;/p&gt;
&lt;p&gt;If you are interested, below you can see the benchmarks for these two &lt;code&gt;dplyr&lt;/code&gt; approaches. We can see that the &lt;code&gt;slice()&lt;/code&gt; approach is much quicker than the &lt;code&gt;mutate()&lt;/code&gt; approach which we would expect since there is much less manipulation of the data going on in the first approach.&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:500px;&#34; class=&#34;highchart html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;hc_opts&#34;:{&#34;title&#34;:{&#34;text&#34;:&#34;&lt;b&gt;data.table Solutions&lt;b&gt;&#34;},&#34;yAxis&#34;:{&#34;title&#34;:{&#34;text&#34;:&#34;&lt;b&gt; Time (ns)&lt;b&gt;&#34;}},&#34;credits&#34;:{&#34;enabled&#34;:false},&#34;exporting&#34;:{&#34;enabled&#34;:false},&#34;plotOptions&#34;:{&#34;series&#34;:{&#34;label&#34;:{&#34;enabled&#34;:false},&#34;turboThreshold&#34;:0,&#34;marker&#34;:{&#34;symbol&#34;:&#34;circle&#34;},&#34;showInLegend&#34;:false},&#34;treemap&#34;:{&#34;layoutAlgorithm&#34;:&#34;squarified&#34;}},&#34;chart&#34;:{&#34;type&#34;:&#34;column&#34;},&#34;xAxis&#34;:{&#34;type&#34;:&#34;category&#34;,&#34;categories&#34;:&#34;&#34;},&#34;series&#34;:[{&#34;g2&#34;:null,&#34;data&#34;:[{&#34;name&#34;:&#34;slice&#34;,&#34;low&#34;:783836,&#34;q1&#34;:1432169,&#34;median&#34;:1787723.5,&#34;q3&#34;:3899602.5,&#34;high&#34;:6866242},{&#34;name&#34;:&#34;mutate&#34;,&#34;low&#34;:2896474,&#34;q1&#34;:4390216.5,&#34;median&#34;:5379481.5,&#34;q3&#34;:8039500.5,&#34;high&#34;:12953443}],&#34;type&#34;:&#34;boxplot&#34;,&#34;id&#34;:null,&#34;name&#34;:&#34;Solution&#34;,&#34;color&#34;:&#34;#6272a4&#34;,&#34;fillColor&#34;:&#34;#f8f8f2&#34;,&#34;lineWidth&#34;:1.5}]},&#34;theme&#34;:{&#34;chart&#34;:{&#34;backgroundColor&#34;:&#34;transparent&#34;}},&#34;conf_opts&#34;:{&#34;global&#34;:{&#34;Date&#34;:null,&#34;VMLRadialGradientURL&#34;:&#34;http =//code.highcharts.com/list(version)/gfx/vml-radial-gradient.png&#34;,&#34;canvasToolsURL&#34;:&#34;http =//code.highcharts.com/list(version)/modules/canvas-tools.js&#34;,&#34;getTimezoneOffset&#34;:null,&#34;timezoneOffset&#34;:0,&#34;useUTC&#34;:true},&#34;lang&#34;:{&#34;contextButtonTitle&#34;:&#34;Chart context menu&#34;,&#34;decimalPoint&#34;:&#34;.&#34;,&#34;downloadJPEG&#34;:&#34;Download JPEG image&#34;,&#34;downloadPDF&#34;:&#34;Download PDF document&#34;,&#34;downloadPNG&#34;:&#34;Download PNG image&#34;,&#34;downloadSVG&#34;:&#34;Download SVG vector image&#34;,&#34;drillUpText&#34;:&#34;Back to {series.name}&#34;,&#34;invalidDate&#34;:null,&#34;loading&#34;:&#34;Loading...&#34;,&#34;months&#34;:[&#34;January&#34;,&#34;February&#34;,&#34;March&#34;,&#34;April&#34;,&#34;May&#34;,&#34;June&#34;,&#34;July&#34;,&#34;August&#34;,&#34;September&#34;,&#34;October&#34;,&#34;November&#34;,&#34;December&#34;],&#34;noData&#34;:&#34;No data to display&#34;,&#34;numericSymbols&#34;:[&#34;k&#34;,&#34;M&#34;,&#34;G&#34;,&#34;T&#34;,&#34;P&#34;,&#34;E&#34;],&#34;printChart&#34;:&#34;Print chart&#34;,&#34;resetZoom&#34;:&#34;Reset zoom&#34;,&#34;resetZoomTitle&#34;:&#34;Reset zoom level 1:1&#34;,&#34;shortMonths&#34;:[&#34;Jan&#34;,&#34;Feb&#34;,&#34;Mar&#34;,&#34;Apr&#34;,&#34;May&#34;,&#34;Jun&#34;,&#34;Jul&#34;,&#34;Aug&#34;,&#34;Sep&#34;,&#34;Oct&#34;,&#34;Nov&#34;,&#34;Dec&#34;],&#34;thousandsSep&#34;:&#34; &#34;,&#34;weekdays&#34;:[&#34;Sunday&#34;,&#34;Monday&#34;,&#34;Tuesday&#34;,&#34;Wednesday&#34;,&#34;Thursday&#34;,&#34;Friday&#34;,&#34;Saturday&#34;]}},&#34;type&#34;:&#34;chart&#34;,&#34;fonts&#34;:[],&#34;debug&#34;:false},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;sparklyr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;code&gt;sparklyr&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;A great feature of &lt;code&gt;dplyr&lt;/code&gt; is its ability to execute your R code on a Spark cluster. To achieve this, &lt;code&gt;dplyr&lt;/code&gt; uses the &lt;a href=&#34;https://github.com/tidyverse/dbplyr&#34;&gt;&lt;code&gt;dbplyr&lt;/code&gt;&lt;/a&gt; package which translates your &lt;code&gt;dplyr&lt;/code&gt; code into Spark SQL code which can then be passed to the Spark connection to be executed by your Spark cluster. The problem, however, is that not all &lt;code&gt;dplyr&lt;/code&gt; verbs translate.&lt;/p&gt;
&lt;p&gt;First, let’s set up a local Spark cluster and upload the &lt;code&gt;mtcars&lt;/code&gt; data to it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sparklyr)
sc &amp;lt;- spark_connect(master = &amp;quot;local&amp;quot;)
mtcars_spark &amp;lt;- copy_to(sc, mtcars, &amp;quot;mtcars&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can explore our first &lt;code&gt;dplyr&lt;/code&gt; example by attempting to execute it on the Spark cluster. We use &lt;code&gt;dbplyr::sql_render()&lt;/code&gt; as the final part of the chain to try and see the SQL code that &lt;code&gt;dbplyr&lt;/code&gt; translates the &lt;code&gt;dplyr&lt;/code&gt; code to.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_spark %&amp;gt;% 
  group_by(cyl) %&amp;gt;% 
  arrange(desc(mpg)) %&amp;gt;% 
  slice(1) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  dbplyr::sql_render()
# Error in slice_.tbl_spark(.data, .dots = compat_as_lazy_dots(...)): Slice is not supported in this version of sparklyr&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this instance, &lt;code&gt;dplyr&lt;/code&gt; tells us that we cannot use &lt;code&gt;slice()&lt;/code&gt; since it is not currently supported by &lt;code&gt;sparklyr&lt;/code&gt;, this is because there is no direct translation from &lt;code&gt;slice()&lt;/code&gt; to Spark SQL code. So let’s try our second approach.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_spark %&amp;gt;% 
  group_by(cyl) %&amp;gt;% 
  arrange(desc(mpg)) %&amp;gt;% 
  mutate(row_number = row_number()) %&amp;gt;% 
  filter(row_number == 1) %&amp;gt;% 
  select(-row_number) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  dbplyr::sql_render()
# &amp;lt;SQL&amp;gt; SELECT `car`, `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`
# FROM (SELECT `car`, `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, ROW_NUMBER() OVER (PARTITION BY `cyl` ORDER BY `mpg` DESC) AS `row_number`
# FROM (SELECT *
# FROM `mtcars`
# ORDER BY `mpg` DESC) `dbplyr_001`) `dbplyr_002`
# WHERE (`row_number` = 1.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we see that the function &lt;code&gt;row_number()&lt;/code&gt; does translate; since it is a ranking function which mimics the functions described in SQL2003 (see &lt;code&gt;?ranking&lt;/code&gt;), &lt;code&gt;dbplyr&lt;/code&gt; knows the equivalent SQL code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_spark %&amp;gt;% 
  group_by(cyl) %&amp;gt;% 
  arrange(desc(mpg)) %&amp;gt;% 
  mutate(row_number = row_number()) %&amp;gt;% 
  filter(row_number == 1) %&amp;gt;% 
  select(-row_number) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  collect()
# # A tibble: 3 x 12
#   car       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
# 1 Hornet…  21.4     6 258     110  3.08  3.22  19.4     1     0     3     1
# 2 Toyota…  33.9     4  71.1    65  4.22  1.84  19.9     1     1     4     1
# 3 Pontia…  19.2     8 400     175  3.08  3.84  17.0     0     0     3     2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So really when it comes to using &lt;code&gt;dplyr&lt;/code&gt; for data manipulation in Spark it sometimes requires some persistence in finding a function which will translate nicely to Spark SQL, especially if you don’t want to use the often slow &lt;code&gt;spark_apply()&lt;/code&gt; function to apply an R function to a Spark object. Although I would recommend reading the &lt;a href=&#34;https://spark.rstudio.com/dplyr/&#34;&gt;&lt;code&gt;sparklyr&lt;/code&gt; documentation&lt;/a&gt;, it can often be a little light on the details and so for a more detailed look at how to send R code to be executed on your Spark cluster, check out my colleague Jozef’s &lt;a href=&#34;https://jozef.io/r201-spark-r-1/#an-r-function-translated-to-spark-sql&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a side note, should you not be able to find an R function which will translate to SQL code, it is always worth checking out the list of &lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF&#34;&gt;Hive Operators and User-Defined Functions (UDFs)&lt;/a&gt;. UDFs are functions that are built for specific purposes to perform operations like Mathematical, arithmetic, logical and relational on the operands of table column names.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This concludes this series of blog posts in which we have seen how we can select a single row from a &lt;code&gt;data.frame&lt;/code&gt;, &lt;code&gt;data.table&lt;/code&gt; or &lt;code&gt;tibble&lt;/code&gt; for each group, where a column in that group is at the maximum value for its group. In this post, we saw how this task is quite easy to do with &lt;code&gt;dplyr&lt;/code&gt;’s &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;slice()&lt;/code&gt; combination of functions. We then saw how we can translate our &lt;code&gt;dplyr&lt;/code&gt; code to be executed as SQL code on a Spark cluster; though not all &lt;code&gt;dplyr&lt;/code&gt; “verbs” currently translate into SQL. To that end, it is often worth looking to see if there is a Hive User-Defined Function to perform the data manipulation task at hand if there is not a direct translation of a &lt;code&gt;dplyr&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Including Optional Functionality from Other Packages in Your Code</title>
      <link>/2019/09/05/including-optional-functionality-from-other-packages-in-your-code/</link>
      <pubDate>Thu, 05 Sep 2019 21:13:14 -0500</pubDate>
      
      <guid>/2019/09/05/including-optional-functionality-from-other-packages-in-your-code/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Let’s say you want to write a function with optional functionality which is dependent on the installation of a package that your colleague may not have installed. For example, let’s say you want to have an option to return a &lt;code&gt;data.table&lt;/code&gt; (or a &lt;code&gt;tibble&lt;/code&gt;) instead of a &lt;code&gt;data.frame&lt;/code&gt;, but in this case you don’t want to force your function’s user to have to install &lt;code&gt;data.table&lt;/code&gt; (or &lt;code&gt;tibble&lt;/code&gt; - and its dependencies) just to use your function. Maybe they can’t install it because they are restricted to do so by their IT department or maybe they are working offline. Is it possible to do this?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-toy-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A Toy Example&lt;/h1&gt;
&lt;p&gt;Let’s say we have a simple function which takes a &lt;code&gt;data.frame&lt;/code&gt; and adds a new column which is a multiplication of an existing column, before returning the whole &lt;code&gt;data.frame&lt;/code&gt; with that new column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toy_function &amp;lt;- function(data, column, multiple = 2L, as_data_table = FALSE) {
  stopifnot(is.integer(multiple) || is.numeric(multiple))
  new_column_name &amp;lt;- paste(column, multiple, sep = &amp;quot;_&amp;quot;)
  data[, new_column_name] &amp;lt;- data[, column] * multiple
  if (as_data_table) data &amp;lt;- data.table::setDT(data)
  return(data)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running this function with &lt;code&gt;as_data_table = TRUE&lt;/code&gt; without &lt;code&gt;data.table&lt;/code&gt; installed will give the following error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toy_function(mtcars, &amp;quot;mpg&amp;quot;, as_data_table = TRUE)
# Error in loadNamespace(name) : there is no package called ‘data.table’&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a frustration for the user. This also means that the whole function no longer works and doesn’t return anything. So what can we do? Well, this is where the function &lt;code&gt;requireNamespace()&lt;/code&gt; comes in handy.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;requireNamespace&lt;/code&gt; is a wrapper for &lt;code&gt;loadNamespace&lt;/code&gt; analogous to require that returns a &lt;code&gt;logical&lt;/code&gt; value.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Using &lt;code&gt;requireNamespace()&lt;/code&gt;, we can test whether or not the &lt;code&gt;data.table&lt;/code&gt; package can be loaded from the user’s library before running certain functionality. Let’s take a look at how this changes our function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toy_function &amp;lt;- function(data, column, multiple = 2L, as_data_table = FALSE) {
  stopifnot(is.integer(multiple) || is.numeric(multiple))
  new_column_name &amp;lt;- paste(column, multiple, sep = &amp;quot;_&amp;quot;)
  data[, new_column_name] &amp;lt;- data[, column] * multiple
  if (as_data_table) {
    if (!requireNamespace(&amp;quot;data.table&amp;quot;, quietly = TRUE)) {
      warning(&amp;quot;Please install package &amp;#39;data.table&amp;#39; when using &amp;#39;as_data_table = TRUE&amp;#39;&amp;quot;)
      return(data)
    }
    data &amp;lt;- data.table::setDT(data)
  }
  return(data)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now when we run our function, the function will check for a &lt;code&gt;data.table&lt;/code&gt; installation and if it is not available, it will warn us that we need to install &lt;code&gt;data.table&lt;/code&gt; in order to use this functionality; yet it will still return the manipulated data, just as a &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toy_function(mtcars, &amp;quot;mpg&amp;quot;, as_data_table = TRUE)
#                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb mpg_2
# Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  42.0
# Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  42.0
# Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1  45.6
# ...
# Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  39.4
# Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  30.0
# Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  42.8
# Warning message:
# In toy_function(mtcars, &amp;quot;mpg&amp;quot;, as_data_table = TRUE) :
#   Please install package &amp;#39;data.table&amp;#39; when using &amp;#39;as_data_table = TRUE&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A real example of this can be seen in the &lt;a href=&#34;https://github.com/fstpackage/fst&#34;&gt;&lt;code&gt;fst&lt;/code&gt;&lt;/a&gt; package. When using the &lt;code&gt;fst::read_fst()&lt;/code&gt; function, the user has the option to return their loaded data &lt;a href=&#34;https://github.com/fstpackage/fst/blob/develop/R/fst.R#L172&#34;&gt;as a &lt;code&gt;data.table&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I really like how this way of using optional functionality does not force additional package downloads on people and also means that your code remains usable on restricted servers or offline. It’s also a great way to not clog up people’s libraries (I’m looking at you &lt;code&gt;tidyverse&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;package-development&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Package Development&lt;/h1&gt;
&lt;p&gt;This solution extends further when developing an R package. My current team is due to start utilising Spark, though our Spark cluster is not yet configured. I have therefore been testing new functionality using a local Spark cluster on our dev environment. Our production environment does not have the &lt;code&gt;sparklyr&lt;/code&gt; package installed yet and so I cannot include any &lt;code&gt;sparklyr&lt;/code&gt; code within my codebase…or can I?&lt;/p&gt;
&lt;p&gt;Typically when your package relies on another package for functionality, you list that package as an &lt;code&gt;Import&lt;/code&gt; within your package’s &lt;code&gt;DESCRIPTION&lt;/code&gt; file. But what this typically means is that when someone installs your package, they will also need to install the &lt;code&gt;Import&lt;/code&gt;s. However if the dependency is not available to install, you will receive the following error upon installation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;==&amp;gt; R CMD INSTALL --no-multiarch --with-keep.source mypackage

* installing to library ‘/Library/Frameworks/R.framework/Versions/3.5/Resources/library’
ERROR: dependency ‘sparklyr’ is not available for package ‘mypackage’
* removing ‘/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mypackage’

Exited with status 1.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am forgoing the idea that it probably isn’t best practice to include non-production code which will not work in your package, this blog post is for the purposes of demonstration only; the following is what you &lt;em&gt;could&lt;/em&gt; do.&lt;/p&gt;
&lt;p&gt;Removing &lt;code&gt;sparklyr&lt;/code&gt; from the &lt;code&gt;Import&lt;/code&gt; list would allow us to install the package but we would then face two new issues. Firstly, end users could potentially run the function (even if it isn’t exported) and be faced with that same unhelpful error message we saw earlier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_function()
# Error in loadNamespace(name) : there is no package called ‘sparklyr’&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Secondly, from a developer’s point of view, the &lt;code&gt;R CMD check&lt;/code&gt; would fail - which would in turn fail any CI/CD pipelines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::check()
# ...
# ❯ checking dependencies in R code ... WARNING
#   &amp;#39;::&amp;#39; or &amp;#39;:::&amp;#39; import not declared from: ‘sparklyr’&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So within my function, I simply place the below code (or similar) and if the user tries to run the function, it will simply stop and tell them they need to install the &lt;code&gt;sparklyr&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!requireNamespace(&amp;quot;sparklyr&amp;quot;, quietly = TRUE)) {
  stop(&amp;quot;Package sparklyr needed.&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will subsequently pass the &lt;code&gt;R CMD check&lt;/code&gt;. Were this an open source package, I could add &lt;code&gt;sparklyr&lt;/code&gt; to the &lt;code&gt;Suggests&lt;/code&gt; field of the &lt;code&gt;DESCRIPTION&lt;/code&gt; file such that users could install the &lt;code&gt;sparklyr&lt;/code&gt; package to get the additional functionality if they wanted it (this is exactly what the &lt;code&gt;fst&lt;/code&gt; package does).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;So to conclude if you want to include functionality in your code which relies on other packages but are worried about people not having access to those packages, or simply don’t want to force your users to have to install the additional packages, then consider &lt;code&gt;requireNamespace()&lt;/code&gt;. This is a great way of offering additional functionality without the need to clog up user’s libraries.&lt;/p&gt;
&lt;p&gt;Credit goes to my colleague &lt;a href=&#34;https://twitter.com/jozefhajnala&#34;&gt;Jozef Hajnala&lt;/a&gt; who pointed out this really neat trick!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Extending sparklyr: Data Types</title>
      <link>/2018/03/08/extending-sparklyr-data-types/</link>
      <pubDate>Thu, 08 Mar 2018 21:13:14 -0500</pubDate>
      
      <guid>/2018/03/08/extending-sparklyr-data-types/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;TL;DR&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;sparklyr&lt;/code&gt; maps R data types and data storage types to Scala, but it doesn’t handle all data storage types. This blog post discusses how to generate Scala data storage types from the R side, that are not generated by &lt;code&gt;sparklyr&lt;/code&gt;. You can do this by using the &lt;code&gt;sparklyr::invoke_new&lt;/code&gt; function to generate the objects you want in Java or Scala, for example a &lt;code&gt;java.util.ArrayList&lt;/code&gt;, and then &lt;code&gt;sparklyr::invoke&lt;/code&gt; methods of the class to add data to it, or convert it to the type you need. Read on to see how to deal with different data storage types from the Scala side or skip ahead to see how to &lt;a href=&#34;#generating-scala-data-types-from-r&#34;&gt;generate Scala data storage types from R&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;When working to &lt;a href=&#34;http://spark.rstudio.com/extensions/&#34;&gt;extend&lt;/a&gt; the &lt;code&gt;sparklyr&lt;/code&gt; package, for example to call custom Scala libraries, oftentimes you will come across Scala methods which require you to use different data storage types to those automatically handled by &lt;code&gt;sparklyr&lt;/code&gt;. When using the &lt;code&gt;invoke&lt;/code&gt; family of functions, R data types map to Scala data types, but &lt;code&gt;sparklyr&lt;/code&gt; &lt;a href=&#34;https://github.com/rstudio/sparklyr/issues/1324&#34;&gt;currently&lt;/a&gt; only handles certain R data storage type mappings. The below table shows the data mappings currently handled by &lt;code&gt;sparklyr&lt;/code&gt;:&lt;/p&gt;
&lt;table style=&#34;width:100%&#34;&gt;
&lt;tr&gt;
&lt;th&gt;
R Type
&lt;/th&gt;
&lt;th&gt;
Scala Type
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
logical
&lt;/td&gt;
&lt;td&gt;
Boolean
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
numeric
&lt;/td&gt;
&lt;td&gt;
Double
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
integer
&lt;/td&gt;
&lt;td&gt;
Integer
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
character
&lt;/td&gt;
&lt;td&gt;
String
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
list
&lt;/td&gt;
&lt;td&gt;
Array
&lt;/td&gt;
&lt;/tr&gt;
&lt;caption&gt;
Table 1: R to Scala type mappings available in &lt;code&gt;sparklyr&lt;/code&gt;
&lt;/caption&gt;
&lt;/table&gt;
&lt;p&gt;So Scala functions with parameters that require a &lt;code&gt;List&lt;/code&gt; or a &lt;code&gt;Seq&lt;/code&gt;, for example, need to be handled in a different way. There are two ways we can approach this problem; from the Scala side and from the R side. We will explore both approaches.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-scala-data-types&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Other Scala Data Types&lt;/h1&gt;
&lt;div id=&#34;solutions-from-the-scala-side&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Solutions from the Scala Side&lt;/h2&gt;
&lt;p&gt;There are several ways that this issue can be overcome from the Scala side, here we highlight three: &lt;a href=&#34;#using-different-data-types-in-scala&#34;&gt;changing the data type&lt;/a&gt; used within Scala; using &lt;a href=&#34;#using-overloading&#34;&gt;overloading&lt;/a&gt;; and defining a &lt;a href=&#34;#defining-a-new-scala-class&#34;&gt;specific R class&lt;/a&gt; to be called from R. These are discussed in detail below.&lt;/p&gt;
&lt;div id=&#34;using-different-data-types-in-scala&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using Different Data Types in Scala&lt;/h3&gt;
&lt;p&gt;One obvous way we could fix this problem is to rewrite the Scala code to use a different parameter type in the Scala method. For example, we could use an &lt;code&gt;Array&lt;/code&gt; which would require us passing a &lt;code&gt;list()&lt;/code&gt; on the R side. However, this is not ideal if your project is large, has lots of legacy code and uses other APIs such as &lt;code&gt;PySpark&lt;/code&gt;; you may end up changing a lot of code.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-overloading&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using Overloading&lt;/h3&gt;
&lt;p&gt;We can instead use &lt;a href=&#34;https://www.javatpoint.com/scala-method-overloading&#34;&gt;overloading&lt;/a&gt;, which allows us to define methods of same name, in the same class, but having either different parameters or data types, though this &lt;a href=&#34;https://stackoverflow.com/questions/2510108/why-avoid-method-overloading&#34;&gt;has many issues&lt;/a&gt;. We would also need to write additional tests for the additional methods. You can think of this as working like R’s S3 methods - for S3 methods the method behaviour will change based on the object’s class.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;defining-a-new-scala-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Defining A New Scala Class&lt;/h3&gt;
&lt;p&gt;To avoid the possible issues of overloading, we can define two separate classes, &lt;code&gt;myClass&lt;/code&gt; and &lt;code&gt;myClassR&lt;/code&gt;. These will both call upon the same underlying &lt;a href=&#34;https://docs.scala-lang.org/overviews/core/implicit-classes.html&#34;&gt;implicit&lt;/a&gt; class which does the bulk of the work for the method. The difference is the data types that are passed into &lt;code&gt;myClass&lt;/code&gt; and &lt;code&gt;myClassR&lt;/code&gt;. &lt;code&gt;myClass&lt;/code&gt; will take the data type you want to use, whereas &lt;code&gt;myClassR&lt;/code&gt; will take the data type passed to it by &lt;code&gt;sparklyr&lt;/code&gt; and then convert it before calling the implicit. Of course using this approach effectively doubles our code and is therefore very wasteful; we would also again, need to write additional tests for this new class.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;solutions-from-the-r-side&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Solutions from the R Side&lt;/h2&gt;
&lt;div id=&#34;generating-scala-data-storage-types-from-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Generating Scala Data Storage Types from R&lt;/h3&gt;
&lt;p&gt;We can actually forgo any changes on the Scala side of our code by generating what we need on the R side. Imagine we wanted to generate a Scala &lt;code&gt;Seq&lt;/code&gt; as an example, first we create a Java &lt;code&gt;ArrayList&lt;/code&gt; in the Spark environment and incrementally &lt;code&gt;add&lt;/code&gt; data to it using the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sparklyr)
sc &amp;lt;- spark_connect(master = &amp;quot;local&amp;quot;)
# map some R vector `x` to a java ArrayList
x &amp;lt;- c(1, 2, 3)
al &amp;lt;- invoke_new(sc, &amp;quot;java.util.ArrayList&amp;quot;)
lapply(x, FUN = function(y){invoke(al, &amp;quot;add&amp;quot;, y)})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note we don’t need to reassign the results of the &lt;code&gt;lapply&lt;/code&gt; because it is adding values to the Scala &lt;code&gt;List&lt;/code&gt; in the JVM. Then using the &lt;a href=&#34;https://www.scala-lang.org/api/2.12.3/scala/collection/JavaConversions$.html&#34;&gt;&lt;code&gt;JavaConversions&lt;/code&gt; Scala package&lt;/a&gt;, we convert the &lt;code&gt;Array&lt;/code&gt; to a &lt;code&gt;Seq&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;invoke_static(sc, &amp;quot;scala.collection.JavaConversions&amp;quot;, &amp;quot;asScalaBuffer&amp;quot;, al) %&amp;gt;%
  invoke(&amp;quot;toSeq&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Putting this all together in a function gives&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scala_seq &amp;lt;- function(sc, x) {
  al &amp;lt;- invoke_new(sc, &amp;quot;java.util.ArrayList&amp;quot;)
  lapply(
    x,
    FUN = function(y) {
      invoke(al, &amp;quot;add&amp;quot;, y)
    }
  )
  invoke_static(sc, &amp;quot;scala.collection.JavaConversions&amp;quot;, &amp;quot;asScalaBuffer&amp;quot;, al) %&amp;gt;%
    invoke(&amp;quot;toSeq&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calling this function returns a reference to the Scala object (&lt;code&gt;spark_jobj&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# connect to spark
sc &amp;lt;- sparklyr::spark_connect(master = &amp;quot;local&amp;quot;)

# create a scala seq object
scala_seq(sc, c(1, 2, 3))
# &amp;lt;jobj[16]&amp;gt;
#   scala.collection.convert.Wrappers$JListWrapper
#   Buffer(1.0, 2.0, 3.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will note that the output we have received tells us we have created a &lt;code&gt;Buffer&lt;/code&gt; but &lt;code&gt;Buffer&lt;/code&gt; (and &lt;code&gt;List&lt;/code&gt;) both &lt;a href=&#34;https://stackoverflow.com/questions/11126577/why-are-buffer-and-list-objects-equal-even-they-are-from-different-classes&#34;&gt;belong to the same category (sequence)&lt;/a&gt;. If what we needed was actually a &lt;code&gt;List&lt;/code&gt; object, then we simply have to &lt;code&gt;invoke&lt;/code&gt; the &lt;code&gt;toList&lt;/code&gt; method on a &lt;code&gt;Seq&lt;/code&gt; (or &lt;code&gt;Buffer&lt;/code&gt;) object. The below function shows this in action, again this returns a reference to the Scala object (&lt;code&gt;spark_jobj&lt;/code&gt;) to the R console.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scala_list &amp;lt;- function(sc, x) {
  scala_seq(sc, x) %&amp;gt;%
    invoke(&amp;quot;toList&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a scala list
scala_list(sc, c(1, 2, 3))
# &amp;lt;jobj[21]&amp;gt;
#   scala.collection.immutable.$colon$colon
#   List(1.0, 2.0, 3.0)

# disconnect the spark connection
spark_disconnect(sc = sc)
# NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similar results can be achieved for other data types. These new data storage types can now be used in Scala function calls when extending &lt;code&gt;sparklyr&lt;/code&gt;, we simply generate the data in the JVM and pass the reference to the function we &lt;code&gt;invoke&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>